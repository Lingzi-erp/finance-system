"""
å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨æœåŠ¡
ä½¿ç”¨ APScheduler å®ç°è‡ªåŠ¨å¤‡ä»½ç­‰å®šæ—¶ä»»åŠ¡
"""

import os
import shutil
import logging
from datetime import datetime
from typing import Optional
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

from app.core.config import settings

logger = logging.getLogger(__name__)

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler: Optional[AsyncIOScheduler] = None


def get_backup_dir() -> str:
    """è·å–å¤‡ä»½ç›®å½•"""
    db_url = settings.SQLITE_DATABASE_URI
    if db_url.startswith("sqlite:///"):
        db_path = db_url.replace("sqlite:///", "")
    elif db_url.startswith("sqlite+aiosqlite:///"):
        db_path = db_url.replace("sqlite+aiosqlite:///", "")
    else:
        db_path = "./finance_system.db"
    backup_dir = os.path.join(os.path.dirname(os.path.abspath(db_path)), "backups")
    os.makedirs(backup_dir, exist_ok=True)
    return backup_dir


def get_db_path() -> str:
    """è·å–æ•°æ®åº“æ–‡ä»¶è·¯å¾„"""
    db_url = settings.SQLITE_DATABASE_URI
    if db_url.startswith("sqlite:///"):
        return db_url.replace("sqlite:///", "")
    elif db_url.startswith("sqlite+aiosqlite:///"):
        return db_url.replace("sqlite+aiosqlite:///", "")
    return "./finance_system.db"


def auto_backup():
    """æ‰§è¡Œè‡ªåŠ¨å¤‡ä»½ä»»åŠ¡"""
    try:
        db_path = get_db_path()
        backup_dir = get_backup_dir()
        
        # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(db_path):
            logger.warning(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
            return
        
        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶åï¼ˆå¸¦ auto_ å‰ç¼€æ ‡è¯†è‡ªåŠ¨å¤‡ä»½ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"auto_backup_{timestamp}.db"
        backup_path = os.path.join(backup_dir, backup_filename)
        
        # å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
        shutil.copy2(db_path, backup_path)
        
        stat = os.stat(backup_path)
        size_mb = stat.st_size / 1024 / 1024
        
        logger.info(f"âœ… è‡ªåŠ¨å¤‡ä»½å®Œæˆ: {backup_filename} ({size_mb:.2f} MB)")
        
        # æ¸…ç†æ—§çš„è‡ªåŠ¨å¤‡ä»½ï¼ˆä¿ç•™æœ€è¿‘ N ä¸ªï¼‰
        cleanup_old_backups(backup_dir, keep_count=settings.AUTO_BACKUP_KEEP_COUNT)
        
    except Exception as e:
        logger.error(f"âŒ è‡ªåŠ¨å¤‡ä»½å¤±è´¥: {str(e)}")


def cleanup_old_backups(backup_dir: str, keep_count: int = 7):
    """æ¸…ç†æ—§çš„è‡ªåŠ¨å¤‡ä»½ï¼Œåªä¿ç•™æœ€è¿‘çš„ N ä¸ª"""
    try:
        # è·å–æ‰€æœ‰è‡ªåŠ¨å¤‡ä»½æ–‡ä»¶
        auto_backups = []
        for filename in os.listdir(backup_dir):
            if filename.startswith("auto_backup_") and filename.endswith(".db"):
                filepath = os.path.join(backup_dir, filename)
                stat = os.stat(filepath)
                auto_backups.append({
                    "filename": filename,
                    "filepath": filepath,
                    "mtime": stat.st_mtime
                })
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        auto_backups.sort(key=lambda x: x["mtime"], reverse=True)
        
        # åˆ é™¤è¶…å‡ºä¿ç•™æ•°é‡çš„å¤‡ä»½
        if len(auto_backups) > keep_count:
            for backup in auto_backups[keep_count:]:
                os.remove(backup["filepath"])
                logger.info(f"ğŸ—‘ï¸ æ¸…ç†æ—§å¤‡ä»½: {backup['filename']}")
                
    except Exception as e:
        logger.warning(f"æ¸…ç†æ—§å¤‡ä»½æ—¶å‡ºé”™: {str(e)}")


def init_scheduler():
    """åˆå§‹åŒ–å¹¶å¯åŠ¨è°ƒåº¦å™¨"""
    global scheduler
    
    if not settings.AUTO_BACKUP_ENABLED:
        logger.info("ğŸ“¦ è‡ªåŠ¨å¤‡ä»½å·²ç¦ç”¨")
        return
    
    scheduler = AsyncIOScheduler()
    
    # æ·»åŠ è‡ªåŠ¨å¤‡ä»½ä»»åŠ¡
    # é»˜è®¤æ¯å¤©å‡Œæ™¨ 3 ç‚¹æ‰§è¡Œ
    scheduler.add_job(
        auto_backup,
        trigger=CronTrigger(
            hour=settings.AUTO_BACKUP_HOUR,
            minute=settings.AUTO_BACKUP_MINUTE
        ),
        id="auto_backup",
        name="è‡ªåŠ¨æ•°æ®åº“å¤‡ä»½",
        replace_existing=True
    )
    
    scheduler.start()
    logger.info(f"â° å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨ - è‡ªåŠ¨å¤‡ä»½æ—¶é—´: æ¯å¤© {settings.AUTO_BACKUP_HOUR:02d}:{settings.AUTO_BACKUP_MINUTE:02d}")


def shutdown_scheduler():
    """å…³é—­è°ƒåº¦å™¨"""
    global scheduler
    if scheduler:
        scheduler.shutdown()
        logger.info("â° å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å…³é—­")


def get_scheduler_status() -> dict:
    """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
    global scheduler
    if not scheduler:
        return {
            "enabled": False,
            "running": False,
            "jobs": []
        }
    
    jobs = []
    for job in scheduler.get_jobs():
        jobs.append({
            "id": job.id,
            "name": job.name,
            "next_run_time": job.next_run_time.isoformat() if job.next_run_time else None
        })
    
    return {
        "enabled": settings.AUTO_BACKUP_ENABLED,
        "running": scheduler.running,
        "jobs": jobs
    }


def trigger_backup_now():
    """ç«‹å³è§¦å‘ä¸€æ¬¡å¤‡ä»½ï¼ˆæ‰‹åŠ¨è§¦å‘ï¼‰"""
    auto_backup()

